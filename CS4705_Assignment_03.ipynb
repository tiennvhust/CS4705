{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ece6d38-d93c-49e1-bd09-5f303a7c45e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in c:\\users\\tienvnguyen\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U tensorflow>=1.8.0\n",
    "!pip install tabulate\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load the fashion-mnist pre-shuffled train data and test data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0015b181-a556-420e-9e58-a51635d073ee",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02eddff3-e9ec-4a8e-b4fd-6204131efadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
      "60000 train set\n",
      "10000 test set\n",
      "y = 2 Pullover\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a2028698e0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print training set shape - note there are 60,000 training data of image size of 28x28, 60,000 train labels)\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_test.shape[0], 'test set')\n",
    "\n",
    "# Define the text labels\n",
    "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Pullover\",     # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Sneaker\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9\n",
    "\n",
    "# Image index, you can pick any number between 0 and 59,999\n",
    "img_index = 5\n",
    "# y_train contains the lables, ranging from 0 to 9\n",
    "label_index = y_train[img_index]\n",
    "# Print the label, for example 2 Pullover\n",
    "print (\"y = \" + str(label_index) + \" \" +(fashion_mnist_labels[label_index]))\n",
    "# # Show one of the images from the training dataset\n",
    "plt.imshow(x_train[img_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f119461a-5951-4db5-91f7-c23a97fbdde3",
   "metadata": {},
   "source": [
    "## Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "31f35ac8-1c78-4b03-aa47-e5a9075138cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data - 60000\n",
      "Number of test data - 10000\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "print(\"Number of train data - \" + str(len(x_train)))\n",
    "print(\"Number of test data - \" + str(len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53becc6b-05cb-4a0c-8e1e-f09bf591ebb8",
   "metadata": {},
   "source": [
    "## Split the data into train/validation/test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f9294a70-77d4-4526-9976-fa4bbb250b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (55000, 28, 28, 1) y_train shape: (55000, 10)\n",
      "55000 train set\n",
      "5000 validation set\n",
      "10000 test set\n"
     ]
    }
   ],
   "source": [
    "# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
    "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
    "\n",
    "# Reshape input data from (28, 28) to (28, 28, 1)\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Print training set shape\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training, validation, and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_valid.shape[0], 'validation set')\n",
    "print(x_test.shape[0], 'test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67edd86a-8390-4835-a569-3e3eec6f31e7",
   "metadata": {},
   "source": [
    "## Architecture Comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4db536-719e-4048-814d-cf7f4ad7859b",
   "metadata": {},
   "source": [
    "### Different combination of number of filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c042542-5aa7-4f7e-b311-6a4ddfa78752",
   "metadata": {},
   "source": [
    "Model 1 [(32,2),(64,2), (0.3,0.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3310771b-e526-47e0-b17e-fa8689bda947",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_01 = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model_01.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model_01.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_01.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_01.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model_01.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_01.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_01.add(tf.keras.layers.Flatten())\n",
    "model_01.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model_01.add(tf.keras.layers.Dropout(0.5))\n",
    "model_01.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9affc-998c-4c3f-a5e3-5d83d5cf8ec0",
   "metadata": {},
   "source": [
    "Model 2 [(128,2),(64,2), (0.3,0.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29074ec7-62d5-4296-8683-6bf71e44bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_02 = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model_02.add(tf.keras.layers.Conv2D(filters=128, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model_02.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_02.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_02.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model_02.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_02.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_02.add(tf.keras.layers.Flatten())\n",
    "model_02.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model_02.add(tf.keras.layers.Dropout(0.5))\n",
    "model_02.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8168a87b-0feb-4584-83a8-2349ced02064",
   "metadata": {},
   "source": [
    "### Different combinations of kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97aa9d5-cc95-43c4-b82b-d0d087f2a0dd",
   "metadata": {},
   "source": [
    "Model 3 [(64,4),(32,4), (0.3,0.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28943cfb-ecda-4cca-accf-149ca4cdf418",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_03 = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model_03.add(tf.keras.layers.Conv2D(filters=64, kernel_size=4, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model_03.add(tf.keras.layers.MaxPooling2D(pool_size=4))\n",
    "model_03.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_03.add(tf.keras.layers.Conv2D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model_03.add(tf.keras.layers.MaxPooling2D(pool_size=4))\n",
    "model_03.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_03.add(tf.keras.layers.Flatten())\n",
    "model_03.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model_03.add(tf.keras.layers.Dropout(0.5))\n",
    "model_03.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2487f5c9-5f18-4f64-a206-5241f80e9a0e",
   "metadata": {},
   "source": [
    "Model 4 [(64,2),(32,4), (0.3,0.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca817f3f-4a33-4a3e-857e-368946cb3975",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_04 = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model_04.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "model_04.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_04.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_04.add(tf.keras.layers.Conv2D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model_04.add(tf.keras.layers.MaxPooling2D(pool_size=4))\n",
    "model_04.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_04.add(tf.keras.layers.Flatten())\n",
    "model_04.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model_04.add(tf.keras.layers.Dropout(0.5))\n",
    "model_04.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743e40f9-dc63-4625-92d6-06c562ab1e16",
   "metadata": {},
   "source": [
    "### Different combinations of kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a211c4-46c4-415d-8bf4-e247a1d9e8ba",
   "metadata": {},
   "source": [
    "Model 5 [(64,2),(32,2), (0.2,0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "50684d6d-a23a-411c-a13f-e7d5bf2b6af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_05 = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model_05.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "model_05.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_05.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model_05.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model_05.add(tf.keras.layers.MaxPooling2D(pool_size=3))\n",
    "model_05.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model_05.add(tf.keras.layers.Flatten())\n",
    "model_05.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model_05.add(tf.keras.layers.Dropout(0.5))\n",
    "model_05.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e29aae-5e0e-4e52-aeb0-a5e8c0fb03bf",
   "metadata": {},
   "source": [
    "Model 6 [(64,2),(32,2), (0.4,0.4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c75887fd-7f6a-469e-84b2-2ea03ded6f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_06 = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model_06.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "model_06.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_06.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "model_06.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model_06.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_06.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "model_06.add(tf.keras.layers.Flatten())\n",
    "model_06.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model_06.add(tf.keras.layers.Dropout(0.5))\n",
    "model_06.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2775d38-a7ab-445c-b1c3-4604c44b3c38",
   "metadata": {},
   "source": [
    "### Architecture with more layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c26e67-b43e-4086-b9aa-a3d8dcc23381",
   "metadata": {},
   "source": [
    "Model 7 [(64,2),(32,2), (32,2),(0.3,0.3,0.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a4f2733a-6aee-4ed8-aab2-f2631f2b16f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_07 = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model_07.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "model_07.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_07.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_07.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model_07.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_07.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_07.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model_07.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_07.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_07.add(tf.keras.layers.Flatten())\n",
    "model_07.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model_07.add(tf.keras.layers.Dropout(0.6))\n",
    "model_07.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d09e5be-f873-4f01-bd75-48c14954bcaa",
   "metadata": {},
   "source": [
    "### Architectures combined changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4150852b-0c6a-481a-95e9-9c487da8f42b",
   "metadata": {},
   "source": [
    "Model 8 [(128,2),(64,2),(64,2), (0.3,0.3,0.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6a96719f-6b9a-478b-8675-762db9cfcbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_08 = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model_08.add(tf.keras.layers.Conv2D(filters=128, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "model_08.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_08.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_08.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model_08.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_08.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_08.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model_08.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_08.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_08.add(tf.keras.layers.Flatten())\n",
    "model_08.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model_08.add(tf.keras.layers.Dropout(0.5))\n",
    "model_08.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007cd268-b084-48b5-9e7c-6106ec26ac37",
   "metadata": {},
   "source": [
    "Model 9 [(128,2),(64,2), (0.2,0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "216bd860-ce5d-430d-ac5c-1f9a5dd6eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_09 = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model_09.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "model_09.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_09.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model_09.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model_09.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_09.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model_09.add(tf.keras.layers.Flatten())\n",
    "model_09.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model_09.add(tf.keras.layers.Dropout(0.5))\n",
    "model_09.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b749d7-b8cd-44c5-8c96-3eb694668b49",
   "metadata": {},
   "source": [
    "Model 10 [(128,4),(64,4), (0.3,0.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ff7b5427-7cc6-4bfe-83d5-ad19ba5dc1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_10 = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model_10.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "model_10.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_10.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_10.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model_10.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model_10.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model_10.add(tf.keras.layers.Flatten())\n",
    "model_10.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model_10.add(tf.keras.layers.Dropout(0.5))\n",
    "model_10.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3d1303-b5e3-4cfe-b06b-8e638e244684",
   "metadata": {},
   "source": [
    "## Compile the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "74acad5e-cb2d-40e4-9131-de8c2db8add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_01.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "model_02.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "model_03.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "model_04.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "model_05.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "model_06.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "model_07.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "model_08.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "model_09.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "model_10.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2213908d-8575-40a1-83f8-a711cea5508f",
   "metadata": {},
   "source": [
    "## Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "de10a2f1-cedc-438f-a0ee-456bba5bac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer_01 = ModelCheckpoint(filepath='model_01.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "checkpointer_02 = ModelCheckpoint(filepath='model_02.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "checkpointer_03 = ModelCheckpoint(filepath='model_03.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "checkpointer_04 = ModelCheckpoint(filepath='model_04.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "checkpointer_05 = ModelCheckpoint(filepath='model_05.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "checkpointer_06 = ModelCheckpoint(filepath='model_06.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "checkpointer_07 = ModelCheckpoint(filepath='model_07.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "checkpointer_08 = ModelCheckpoint(filepath='model_08.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "checkpointer_09 = ModelCheckpoint(filepath='model_09.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "checkpointer_10 = ModelCheckpoint(filepath='model_10.weights.best.hdf5', verbose = 1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "643a0b2d-2380-41c4-acb1-aaa33e263407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.5860 - accuracy: 0.7856\n",
      "Epoch 1: val_loss improved from inf to 0.37104, saving model to model_01.weights.best.hdf5\n",
      "860/860 [==============================] - 27s 30ms/step - loss: 0.5860 - accuracy: 0.7856 - val_loss: 0.3710 - val_accuracy: 0.8710\n",
      "Epoch 2/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.4094 - accuracy: 0.8523\n",
      "Epoch 2: val_loss improved from 0.37104 to 0.32080, saving model to model_01.weights.best.hdf5\n",
      "860/860 [==============================] - 25s 29ms/step - loss: 0.4096 - accuracy: 0.8523 - val_loss: 0.3208 - val_accuracy: 0.8860\n",
      "Epoch 3/10\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.3645 - accuracy: 0.8669\n",
      "Epoch 3: val_loss improved from 0.32080 to 0.28825, saving model to model_01.weights.best.hdf5\n",
      "860/860 [==============================] - 27s 31ms/step - loss: 0.3646 - accuracy: 0.8669 - val_loss: 0.2882 - val_accuracy: 0.8974\n",
      "Epoch 4/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3375 - accuracy: 0.8755\n",
      "Epoch 4: val_loss improved from 0.28825 to 0.28615, saving model to model_01.weights.best.hdf5\n",
      "860/860 [==============================] - 28s 32ms/step - loss: 0.3375 - accuracy: 0.8754 - val_loss: 0.2862 - val_accuracy: 0.8930\n",
      "Epoch 5/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3159 - accuracy: 0.8851\n",
      "Epoch 5: val_loss improved from 0.28615 to 0.25555, saving model to model_01.weights.best.hdf5\n",
      "860/860 [==============================] - 29s 33ms/step - loss: 0.3159 - accuracy: 0.8851 - val_loss: 0.2555 - val_accuracy: 0.9022\n",
      "Epoch 6/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3011 - accuracy: 0.8908\n",
      "Epoch 6: val_loss improved from 0.25555 to 0.24217, saving model to model_01.weights.best.hdf5\n",
      "860/860 [==============================] - 29s 34ms/step - loss: 0.3012 - accuracy: 0.8908 - val_loss: 0.2422 - val_accuracy: 0.9122\n",
      "Epoch 7/10\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.2894 - accuracy: 0.8945\n",
      "Epoch 7: val_loss improved from 0.24217 to 0.23501, saving model to model_01.weights.best.hdf5\n",
      "860/860 [==============================] - 29s 34ms/step - loss: 0.2894 - accuracy: 0.8946 - val_loss: 0.2350 - val_accuracy: 0.9160\n",
      "Epoch 8/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.2773 - accuracy: 0.8972\n",
      "Epoch 8: val_loss improved from 0.23501 to 0.22758, saving model to model_01.weights.best.hdf5\n",
      "860/860 [==============================] - 22s 26ms/step - loss: 0.2773 - accuracy: 0.8972 - val_loss: 0.2276 - val_accuracy: 0.9156\n",
      "Epoch 9/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.2685 - accuracy: 0.9013\n",
      "Epoch 9: val_loss improved from 0.22758 to 0.22519, saving model to model_01.weights.best.hdf5\n",
      "860/860 [==============================] - 23s 26ms/step - loss: 0.2685 - accuracy: 0.9013 - val_loss: 0.2252 - val_accuracy: 0.9172\n",
      "Epoch 10/10\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.2577 - accuracy: 0.9052\n",
      "Epoch 10: val_loss improved from 0.22519 to 0.21979, saving model to model_01.weights.best.hdf5\n",
      "860/860 [==============================] - 22s 25ms/step - loss: 0.2577 - accuracy: 0.9051 - val_loss: 0.2198 - val_accuracy: 0.9210\n"
     ]
    }
   ],
   "source": [
    "# Mark start time\n",
    "start = time.time()\n",
    "model_01.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[checkpointer_01])\n",
    "# Calculate training time\n",
    "time_01 = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a80ae5a5-db64-423a-9580-0b49b3707d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.5642 - accuracy: 0.7940\n",
      "Epoch 1: val_loss improved from inf to 0.36245, saving model to model_02.weights.best.hdf5\n",
      "860/860 [==============================] - 56s 64ms/step - loss: 0.5641 - accuracy: 0.7941 - val_loss: 0.3624 - val_accuracy: 0.8702\n",
      "Epoch 2/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8610\n",
      "Epoch 2: val_loss improved from 0.36245 to 0.31309, saving model to model_02.weights.best.hdf5\n",
      "860/860 [==============================] - 58s 67ms/step - loss: 0.3845 - accuracy: 0.8610 - val_loss: 0.3131 - val_accuracy: 0.8856\n",
      "Epoch 3/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3385 - accuracy: 0.8776\n",
      "Epoch 3: val_loss improved from 0.31309 to 0.27249, saving model to model_02.weights.best.hdf5\n",
      "860/860 [==============================] - 57s 67ms/step - loss: 0.3385 - accuracy: 0.8776 - val_loss: 0.2725 - val_accuracy: 0.9004\n",
      "Epoch 4/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3097 - accuracy: 0.8856\n",
      "Epoch 4: val_loss did not improve from 0.27249\n",
      "860/860 [==============================] - 54s 63ms/step - loss: 0.3097 - accuracy: 0.8856 - val_loss: 0.2764 - val_accuracy: 0.8968\n",
      "Epoch 5/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.2891 - accuracy: 0.8932\n",
      "Epoch 5: val_loss improved from 0.27249 to 0.24168, saving model to model_02.weights.best.hdf5\n",
      "860/860 [==============================] - 68s 79ms/step - loss: 0.2891 - accuracy: 0.8932 - val_loss: 0.2417 - val_accuracy: 0.9106\n",
      "Epoch 6/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.2747 - accuracy: 0.8980\n",
      "Epoch 6: val_loss improved from 0.24168 to 0.23239, saving model to model_02.weights.best.hdf5\n",
      "860/860 [==============================] - 62s 73ms/step - loss: 0.2748 - accuracy: 0.8981 - val_loss: 0.2324 - val_accuracy: 0.9152\n",
      "Epoch 7/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.2577 - accuracy: 0.9054\n",
      "Epoch 7: val_loss improved from 0.23239 to 0.22604, saving model to model_02.weights.best.hdf5\n",
      "860/860 [==============================] - 63s 73ms/step - loss: 0.2577 - accuracy: 0.9054 - val_loss: 0.2260 - val_accuracy: 0.9152\n",
      "Epoch 8/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.2468 - accuracy: 0.9082\n",
      "Epoch 8: val_loss improved from 0.22604 to 0.21328, saving model to model_02.weights.best.hdf5\n",
      "860/860 [==============================] - 59s 69ms/step - loss: 0.2469 - accuracy: 0.9082 - val_loss: 0.2133 - val_accuracy: 0.9196\n",
      "Epoch 9/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.2400 - accuracy: 0.9114\n",
      "Epoch 9: val_loss did not improve from 0.21328\n",
      "860/860 [==============================] - 61s 71ms/step - loss: 0.2400 - accuracy: 0.9114 - val_loss: 0.2134 - val_accuracy: 0.9182\n",
      "Epoch 10/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.2280 - accuracy: 0.9161\n",
      "Epoch 10: val_loss did not improve from 0.21328\n",
      "860/860 [==============================] - 66s 76ms/step - loss: 0.2279 - accuracy: 0.9161 - val_loss: 0.2197 - val_accuracy: 0.9152\n"
     ]
    }
   ],
   "source": [
    "# Mark start time\n",
    "start = time.time()\n",
    "model_02.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[checkpointer_02])\n",
    "# Calculate training time\n",
    "time_02 = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e244a24f-95d0-4aec-a447-ad9b76d4fad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.9074 - accuracy: 0.6626\n",
      "Epoch 1: val_loss improved from inf to 0.49375, saving model to model_03.weights.best.hdf5\n",
      "860/860 [==============================] - 22s 25ms/step - loss: 0.9069 - accuracy: 0.6628 - val_loss: 0.4938 - val_accuracy: 0.8224\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.6011 - accuracy: 0.7811\n",
      "Epoch 2: val_loss improved from 0.49375 to 0.42000, saving model to model_03.weights.best.hdf5\n",
      "860/860 [==============================] - 23s 27ms/step - loss: 0.6011 - accuracy: 0.7811 - val_loss: 0.4200 - val_accuracy: 0.8524\n",
      "Epoch 3/10\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.5344 - accuracy: 0.8057\n",
      "Epoch 3: val_loss improved from 0.42000 to 0.39019, saving model to model_03.weights.best.hdf5\n",
      "860/860 [==============================] - 21s 24ms/step - loss: 0.5347 - accuracy: 0.8056 - val_loss: 0.3902 - val_accuracy: 0.8610\n",
      "Epoch 4/10\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.5021 - accuracy: 0.8175\n",
      "Epoch 4: val_loss improved from 0.39019 to 0.35720, saving model to model_03.weights.best.hdf5\n",
      "860/860 [==============================] - 20s 24ms/step - loss: 0.5022 - accuracy: 0.8175 - val_loss: 0.3572 - val_accuracy: 0.8734\n",
      "Epoch 5/10\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.4779 - accuracy: 0.8260\n",
      "Epoch 5: val_loss improved from 0.35720 to 0.35084, saving model to model_03.weights.best.hdf5\n",
      "860/860 [==============================] - 21s 24ms/step - loss: 0.4780 - accuracy: 0.8259 - val_loss: 0.3508 - val_accuracy: 0.8764\n",
      "Epoch 6/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.4608 - accuracy: 0.8311\n",
      "Epoch 6: val_loss improved from 0.35084 to 0.34390, saving model to model_03.weights.best.hdf5\n",
      "860/860 [==============================] - 21s 25ms/step - loss: 0.4608 - accuracy: 0.8311 - val_loss: 0.3439 - val_accuracy: 0.8768\n",
      "Epoch 7/10\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.4473 - accuracy: 0.8383\n",
      "Epoch 7: val_loss improved from 0.34390 to 0.33601, saving model to model_03.weights.best.hdf5\n",
      "860/860 [==============================] - 21s 25ms/step - loss: 0.4471 - accuracy: 0.8384 - val_loss: 0.3360 - val_accuracy: 0.8762\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.4388 - accuracy: 0.8389\n",
      "Epoch 8: val_loss improved from 0.33601 to 0.32262, saving model to model_03.weights.best.hdf5\n",
      "860/860 [==============================] - 21s 24ms/step - loss: 0.4388 - accuracy: 0.8389 - val_loss: 0.3226 - val_accuracy: 0.8798\n",
      "Epoch 9/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.4288 - accuracy: 0.8442\n",
      "Epoch 9: val_loss improved from 0.32262 to 0.32214, saving model to model_03.weights.best.hdf5\n",
      "860/860 [==============================] - 19s 23ms/step - loss: 0.4288 - accuracy: 0.8442 - val_loss: 0.3221 - val_accuracy: 0.8814\n",
      "Epoch 10/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.4256 - accuracy: 0.8457\n",
      "Epoch 10: val_loss did not improve from 0.32214\n",
      "860/860 [==============================] - 21s 24ms/step - loss: 0.4255 - accuracy: 0.8457 - val_loss: 0.3222 - val_accuracy: 0.8852\n"
     ]
    }
   ],
   "source": [
    "# Mark start time\n",
    "start = time.time()\n",
    "model_03.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[checkpointer_03])\n",
    "# Calculate training time\n",
    "time_03 = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8da2d30f-90bc-465d-9280-92624118a488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.7271 - accuracy: 0.7341\n",
      "Epoch 1: val_loss improved from inf to 0.39736, saving model to model_04.weights.best.hdf5\n",
      "860/860 [==============================] - 48s 55ms/step - loss: 0.7270 - accuracy: 0.7342 - val_loss: 0.3974 - val_accuracy: 0.8568\n",
      "Epoch 2/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.4648 - accuracy: 0.8300\n",
      "Epoch 2: val_loss improved from 0.39736 to 0.33652, saving model to model_04.weights.best.hdf5\n",
      "860/860 [==============================] - 41s 48ms/step - loss: 0.4647 - accuracy: 0.8301 - val_loss: 0.3365 - val_accuracy: 0.8790\n",
      "Epoch 3/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.4088 - accuracy: 0.8484\n",
      "Epoch 3: val_loss improved from 0.33652 to 0.31000, saving model to model_04.weights.best.hdf5\n",
      "860/860 [==============================] - 40s 47ms/step - loss: 0.4087 - accuracy: 0.8484 - val_loss: 0.3100 - val_accuracy: 0.8876\n",
      "Epoch 4/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3788 - accuracy: 0.8612\n",
      "Epoch 4: val_loss improved from 0.31000 to 0.29262, saving model to model_04.weights.best.hdf5\n",
      "860/860 [==============================] - 40s 47ms/step - loss: 0.3787 - accuracy: 0.8612 - val_loss: 0.2926 - val_accuracy: 0.8950\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.3588 - accuracy: 0.8675\n",
      "Epoch 5: val_loss improved from 0.29262 to 0.27186, saving model to model_04.weights.best.hdf5\n",
      "860/860 [==============================] - 41s 47ms/step - loss: 0.3588 - accuracy: 0.8675 - val_loss: 0.2719 - val_accuracy: 0.8994\n",
      "Epoch 6/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3419 - accuracy: 0.8739\n",
      "Epoch 6: val_loss did not improve from 0.27186\n",
      "860/860 [==============================] - 39s 46ms/step - loss: 0.3419 - accuracy: 0.8739 - val_loss: 0.2852 - val_accuracy: 0.8882\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.3328 - accuracy: 0.8761\n",
      "Epoch 7: val_loss improved from 0.27186 to 0.25133, saving model to model_04.weights.best.hdf5\n",
      "860/860 [==============================] - 45s 53ms/step - loss: 0.3328 - accuracy: 0.8761 - val_loss: 0.2513 - val_accuracy: 0.9064\n",
      "Epoch 8/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3239 - accuracy: 0.8812\n",
      "Epoch 8: val_loss improved from 0.25133 to 0.24566, saving model to model_04.weights.best.hdf5\n",
      "860/860 [==============================] - 40s 47ms/step - loss: 0.3239 - accuracy: 0.8812 - val_loss: 0.2457 - val_accuracy: 0.9068\n",
      "Epoch 9/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3144 - accuracy: 0.8843\n",
      "Epoch 9: val_loss improved from 0.24566 to 0.24552, saving model to model_04.weights.best.hdf5\n",
      "860/860 [==============================] - 41s 47ms/step - loss: 0.3145 - accuracy: 0.8843 - val_loss: 0.2455 - val_accuracy: 0.9032\n",
      "Epoch 10/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3090 - accuracy: 0.8856\n",
      "Epoch 10: val_loss improved from 0.24552 to 0.24293, saving model to model_04.weights.best.hdf5\n",
      "860/860 [==============================] - 39s 45ms/step - loss: 0.3091 - accuracy: 0.8856 - val_loss: 0.2429 - val_accuracy: 0.9068\n"
     ]
    }
   ],
   "source": [
    "# Mark start time\n",
    "start = time.time()\n",
    "model_04.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[checkpointer_04])\n",
    "# Calculate training time\n",
    "time_04 = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2967ae01-e5d9-44ae-8b00-2c1a60240081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.6599 - accuracy: 0.7561\n",
      "Epoch 1: val_loss improved from inf to 0.39211, saving model to model_05.weights.best.hdf5\n",
      "860/860 [==============================] - 31s 35ms/step - loss: 0.6598 - accuracy: 0.7561 - val_loss: 0.3921 - val_accuracy: 0.8606\n",
      "Epoch 2/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.4302 - accuracy: 0.8408\n",
      "Epoch 2: val_loss improved from 0.39211 to 0.32577, saving model to model_05.weights.best.hdf5\n",
      "860/860 [==============================] - 35s 40ms/step - loss: 0.4302 - accuracy: 0.8409 - val_loss: 0.3258 - val_accuracy: 0.8820\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8607\n",
      "Epoch 3: val_loss improved from 0.32577 to 0.30460, saving model to model_05.weights.best.hdf5\n",
      "860/860 [==============================] - 34s 40ms/step - loss: 0.3805 - accuracy: 0.8607 - val_loss: 0.3046 - val_accuracy: 0.8878\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.3516 - accuracy: 0.8695\n",
      "Epoch 4: val_loss improved from 0.30460 to 0.27888, saving model to model_05.weights.best.hdf5\n",
      "860/860 [==============================] - 34s 40ms/step - loss: 0.3516 - accuracy: 0.8695 - val_loss: 0.2789 - val_accuracy: 0.8928\n",
      "Epoch 5/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3311 - accuracy: 0.8778\n",
      "Epoch 5: val_loss improved from 0.27888 to 0.26615, saving model to model_05.weights.best.hdf5\n",
      "860/860 [==============================] - 31s 36ms/step - loss: 0.3311 - accuracy: 0.8778 - val_loss: 0.2662 - val_accuracy: 0.9000\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.3165 - accuracy: 0.8813\n",
      "Epoch 6: val_loss improved from 0.26615 to 0.25668, saving model to model_05.weights.best.hdf5\n",
      "860/860 [==============================] - 36s 42ms/step - loss: 0.3165 - accuracy: 0.8813 - val_loss: 0.2567 - val_accuracy: 0.9056\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.3043 - accuracy: 0.8877\n",
      "Epoch 7: val_loss improved from 0.25668 to 0.24958, saving model to model_05.weights.best.hdf5\n",
      "860/860 [==============================] - 37s 43ms/step - loss: 0.3043 - accuracy: 0.8877 - val_loss: 0.2496 - val_accuracy: 0.9058\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.2941 - accuracy: 0.8914\n",
      "Epoch 8: val_loss improved from 0.24958 to 0.24787, saving model to model_05.weights.best.hdf5\n",
      "860/860 [==============================] - 37s 43ms/step - loss: 0.2941 - accuracy: 0.8914 - val_loss: 0.2479 - val_accuracy: 0.9050\n",
      "Epoch 9/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.2856 - accuracy: 0.8939\n",
      "Epoch 9: val_loss improved from 0.24787 to 0.24491, saving model to model_05.weights.best.hdf5\n",
      "860/860 [==============================] - 32s 37ms/step - loss: 0.2856 - accuracy: 0.8939 - val_loss: 0.2449 - val_accuracy: 0.9132\n",
      "Epoch 10/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.2740 - accuracy: 0.8972\n",
      "Epoch 10: val_loss improved from 0.24491 to 0.23125, saving model to model_05.weights.best.hdf5\n",
      "860/860 [==============================] - 35s 40ms/step - loss: 0.2739 - accuracy: 0.8972 - val_loss: 0.2312 - val_accuracy: 0.9142\n"
     ]
    }
   ],
   "source": [
    "# Mark start time\n",
    "start = time.time()\n",
    "model_05.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[checkpointer_05])\n",
    "# Calculate training time\n",
    "time_05 = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2ef554a4-4071-48e4-b6d8-e83d58aba372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.6467 - accuracy: 0.7567\n",
      "Epoch 1: val_loss improved from inf to 0.39150, saving model to model_06.weights.best.hdf5\n",
      "860/860 [==============================] - 28s 32ms/step - loss: 0.6465 - accuracy: 0.7568 - val_loss: 0.3915 - val_accuracy: 0.8586\n",
      "Epoch 2/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.4447 - accuracy: 0.8381\n",
      "Epoch 2: val_loss improved from 0.39150 to 0.34244, saving model to model_06.weights.best.hdf5\n",
      "860/860 [==============================] - 28s 33ms/step - loss: 0.4446 - accuracy: 0.8381 - val_loss: 0.3424 - val_accuracy: 0.8830\n",
      "Epoch 3/10\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.3972 - accuracy: 0.8535\n",
      "Epoch 3: val_loss improved from 0.34244 to 0.30781, saving model to model_06.weights.best.hdf5\n",
      "860/860 [==============================] - 30s 35ms/step - loss: 0.3972 - accuracy: 0.8535 - val_loss: 0.3078 - val_accuracy: 0.8910\n",
      "Epoch 4/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3715 - accuracy: 0.8641\n",
      "Epoch 4: val_loss improved from 0.30781 to 0.29160, saving model to model_06.weights.best.hdf5\n",
      "860/860 [==============================] - 29s 33ms/step - loss: 0.3715 - accuracy: 0.8641 - val_loss: 0.2916 - val_accuracy: 0.8904\n",
      "Epoch 5/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3496 - accuracy: 0.8719\n",
      "Epoch 5: val_loss improved from 0.29160 to 0.27400, saving model to model_06.weights.best.hdf5\n",
      "860/860 [==============================] - 34s 40ms/step - loss: 0.3495 - accuracy: 0.8719 - val_loss: 0.2740 - val_accuracy: 0.9010\n",
      "Epoch 6/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3335 - accuracy: 0.8798\n",
      "Epoch 6: val_loss improved from 0.27400 to 0.27225, saving model to model_06.weights.best.hdf5\n",
      "860/860 [==============================] - 27s 32ms/step - loss: 0.3335 - accuracy: 0.8798 - val_loss: 0.2723 - val_accuracy: 0.8966\n",
      "Epoch 7/10\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.3245 - accuracy: 0.8805\n",
      "Epoch 7: val_loss improved from 0.27225 to 0.25506, saving model to model_06.weights.best.hdf5\n",
      "860/860 [==============================] - 27s 32ms/step - loss: 0.3244 - accuracy: 0.8805 - val_loss: 0.2551 - val_accuracy: 0.9044\n",
      "Epoch 8/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3140 - accuracy: 0.8845\n",
      "Epoch 8: val_loss did not improve from 0.25506\n",
      "860/860 [==============================] - 31s 36ms/step - loss: 0.3140 - accuracy: 0.8845 - val_loss: 0.2556 - val_accuracy: 0.9014\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.3053 - accuracy: 0.8874\n",
      "Epoch 9: val_loss improved from 0.25506 to 0.24696, saving model to model_06.weights.best.hdf5\n",
      "860/860 [==============================] - 27s 32ms/step - loss: 0.3053 - accuracy: 0.8874 - val_loss: 0.2470 - val_accuracy: 0.9036\n",
      "Epoch 10/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.2940 - accuracy: 0.8921\n",
      "Epoch 10: val_loss improved from 0.24696 to 0.24148, saving model to model_06.weights.best.hdf5\n",
      "860/860 [==============================] - 34s 39ms/step - loss: 0.2940 - accuracy: 0.8921 - val_loss: 0.2415 - val_accuracy: 0.9114\n"
     ]
    }
   ],
   "source": [
    "# Mark start time\n",
    "start = time.time()\n",
    "model_06.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[checkpointer_06])\n",
    "# Calculate training time\n",
    "time_06 = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "363b737f-f708-4492-8066-2b9a9ad2411e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.8965 - accuracy: 0.6579\n",
      "Epoch 1: val_loss improved from inf to 0.51818, saving model to model_07.weights.best.hdf5\n",
      "860/860 [==============================] - 33s 38ms/step - loss: 0.8965 - accuracy: 0.6579 - val_loss: 0.5182 - val_accuracy: 0.8022\n",
      "Epoch 2/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.5900 - accuracy: 0.7741\n",
      "Epoch 2: val_loss improved from 0.51818 to 0.43122, saving model to model_07.weights.best.hdf5\n",
      "860/860 [==============================] - 31s 36ms/step - loss: 0.5902 - accuracy: 0.7741 - val_loss: 0.4312 - val_accuracy: 0.8418\n",
      "Epoch 3/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.5217 - accuracy: 0.8047\n",
      "Epoch 3: val_loss improved from 0.43122 to 0.37482, saving model to model_07.weights.best.hdf5\n",
      "860/860 [==============================] - 27s 32ms/step - loss: 0.5216 - accuracy: 0.8047 - val_loss: 0.3748 - val_accuracy: 0.8636\n",
      "Epoch 4/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.4726 - accuracy: 0.8259\n",
      "Epoch 4: val_loss improved from 0.37482 to 0.33667, saving model to model_07.weights.best.hdf5\n",
      "860/860 [==============================] - 26s 30ms/step - loss: 0.4726 - accuracy: 0.8259 - val_loss: 0.3367 - val_accuracy: 0.8796\n",
      "Epoch 5/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.4460 - accuracy: 0.8361\n",
      "Epoch 5: val_loss improved from 0.33667 to 0.31790, saving model to model_07.weights.best.hdf5\n",
      "860/860 [==============================] - 31s 36ms/step - loss: 0.4459 - accuracy: 0.8362 - val_loss: 0.3179 - val_accuracy: 0.8906\n",
      "Epoch 6/10\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.4203 - accuracy: 0.8460\n",
      "Epoch 6: val_loss improved from 0.31790 to 0.30560, saving model to model_07.weights.best.hdf5\n",
      "860/860 [==============================] - 31s 36ms/step - loss: 0.4204 - accuracy: 0.8460 - val_loss: 0.3056 - val_accuracy: 0.8844\n",
      "Epoch 7/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.4041 - accuracy: 0.8526\n",
      "Epoch 7: val_loss improved from 0.30560 to 0.28888, saving model to model_07.weights.best.hdf5\n",
      "860/860 [==============================] - 30s 35ms/step - loss: 0.4042 - accuracy: 0.8526 - val_loss: 0.2889 - val_accuracy: 0.8940\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.3957 - accuracy: 0.8545\n",
      "Epoch 8: val_loss did not improve from 0.28888\n",
      "860/860 [==============================] - 30s 35ms/step - loss: 0.3957 - accuracy: 0.8545 - val_loss: 0.2919 - val_accuracy: 0.8934\n",
      "Epoch 9/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8610\n",
      "Epoch 9: val_loss improved from 0.28888 to 0.28198, saving model to model_07.weights.best.hdf5\n",
      "860/860 [==============================] - 28s 32ms/step - loss: 0.3820 - accuracy: 0.8611 - val_loss: 0.2820 - val_accuracy: 0.8964\n",
      "Epoch 10/10\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.3758 - accuracy: 0.8635\n",
      "Epoch 10: val_loss improved from 0.28198 to 0.27450, saving model to model_07.weights.best.hdf5\n",
      "860/860 [==============================] - 29s 34ms/step - loss: 0.3758 - accuracy: 0.8635 - val_loss: 0.2745 - val_accuracy: 0.8958\n"
     ]
    }
   ],
   "source": [
    "# Mark start time\n",
    "start = time.time()\n",
    "model_07.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[checkpointer_07])\n",
    "# Calculate training time\n",
    "time_07 = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8feb2240-ddd6-48ba-aba9-55ee82ad39de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.7413 - accuracy: 0.7211\n",
      "Epoch 1: val_loss improved from inf to 0.40814, saving model to model_08.weights.best.hdf5\n",
      "860/860 [==============================] - 57s 65ms/step - loss: 0.7410 - accuracy: 0.7212 - val_loss: 0.4081 - val_accuracy: 0.8558\n",
      "Epoch 2/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.4648 - accuracy: 0.8268\n",
      "Epoch 2: val_loss improved from 0.40814 to 0.33193, saving model to model_08.weights.best.hdf5\n",
      "860/860 [==============================] - 56s 65ms/step - loss: 0.4648 - accuracy: 0.8268 - val_loss: 0.3319 - val_accuracy: 0.8818\n",
      "Epoch 3/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.4044 - accuracy: 0.8521\n",
      "Epoch 3: val_loss improved from 0.33193 to 0.31127, saving model to model_08.weights.best.hdf5\n",
      "860/860 [==============================] - 57s 66ms/step - loss: 0.4045 - accuracy: 0.8521 - val_loss: 0.3113 - val_accuracy: 0.8864\n",
      "Epoch 4/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3674 - accuracy: 0.8662\n",
      "Epoch 4: val_loss improved from 0.31127 to 0.27338, saving model to model_08.weights.best.hdf5\n",
      "860/860 [==============================] - 63s 73ms/step - loss: 0.3674 - accuracy: 0.8662 - val_loss: 0.2734 - val_accuracy: 0.9000\n",
      "Epoch 5/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3460 - accuracy: 0.8745\n",
      "Epoch 5: val_loss improved from 0.27338 to 0.26197, saving model to model_08.weights.best.hdf5\n",
      "860/860 [==============================] - 54s 62ms/step - loss: 0.3461 - accuracy: 0.8745 - val_loss: 0.2620 - val_accuracy: 0.9052\n",
      "Epoch 6/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3314 - accuracy: 0.8781\n",
      "Epoch 6: val_loss improved from 0.26197 to 0.25862, saving model to model_08.weights.best.hdf5\n",
      "860/860 [==============================] - 55s 64ms/step - loss: 0.3313 - accuracy: 0.8782 - val_loss: 0.2586 - val_accuracy: 0.9074\n",
      "Epoch 7/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3189 - accuracy: 0.8831\n",
      "Epoch 7: val_loss improved from 0.25862 to 0.24663, saving model to model_08.weights.best.hdf5\n",
      "860/860 [==============================] - 57s 66ms/step - loss: 0.3188 - accuracy: 0.8832 - val_loss: 0.2466 - val_accuracy: 0.9090\n",
      "Epoch 8/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3110 - accuracy: 0.8866\n",
      "Epoch 8: val_loss improved from 0.24663 to 0.23818, saving model to model_08.weights.best.hdf5\n",
      "860/860 [==============================] - 56s 65ms/step - loss: 0.3110 - accuracy: 0.8866 - val_loss: 0.2382 - val_accuracy: 0.9128\n",
      "Epoch 9/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3025 - accuracy: 0.8884\n",
      "Epoch 9: val_loss did not improve from 0.23818\n",
      "860/860 [==============================] - 55s 63ms/step - loss: 0.3024 - accuracy: 0.8884 - val_loss: 0.2469 - val_accuracy: 0.9052\n",
      "Epoch 10/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.2934 - accuracy: 0.8920\n",
      "Epoch 10: val_loss did not improve from 0.23818\n",
      "860/860 [==============================] - 55s 64ms/step - loss: 0.2934 - accuracy: 0.8921 - val_loss: 0.2393 - val_accuracy: 0.9104\n"
     ]
    }
   ],
   "source": [
    "# Mark start time\n",
    "start = time.time()\n",
    "model_08.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[checkpointer_08])\n",
    "# Calculate training time\n",
    "time_08 = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c33762ee-e638-47e3-9721-5f49229af994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.5822 - accuracy: 0.7855\n",
      "Epoch 1: val_loss improved from inf to 0.36438, saving model to model_09.weights.best.hdf5\n",
      "860/860 [==============================] - 29s 33ms/step - loss: 0.5821 - accuracy: 0.7856 - val_loss: 0.3644 - val_accuracy: 0.8712\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.3977 - accuracy: 0.8563\n",
      "Epoch 2: val_loss improved from 0.36438 to 0.31430, saving model to model_09.weights.best.hdf5\n",
      "860/860 [==============================] - 28s 33ms/step - loss: 0.3977 - accuracy: 0.8563 - val_loss: 0.3143 - val_accuracy: 0.8854\n",
      "Epoch 3/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3533 - accuracy: 0.8716\n",
      "Epoch 3: val_loss improved from 0.31430 to 0.29334, saving model to model_09.weights.best.hdf5\n",
      "860/860 [==============================] - 28s 33ms/step - loss: 0.3532 - accuracy: 0.8717 - val_loss: 0.2933 - val_accuracy: 0.8902\n",
      "Epoch 4/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3237 - accuracy: 0.8815\n",
      "Epoch 4: val_loss improved from 0.29334 to 0.26684, saving model to model_09.weights.best.hdf5\n",
      "860/860 [==============================] - 30s 35ms/step - loss: 0.3237 - accuracy: 0.8815 - val_loss: 0.2668 - val_accuracy: 0.9022\n",
      "Epoch 5/10\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.3070 - accuracy: 0.8885\n",
      "Epoch 5: val_loss improved from 0.26684 to 0.25765, saving model to model_09.weights.best.hdf5\n",
      "860/860 [==============================] - 29s 34ms/step - loss: 0.3072 - accuracy: 0.8884 - val_loss: 0.2576 - val_accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.2872 - accuracy: 0.8924\n",
      "Epoch 6: val_loss improved from 0.25765 to 0.23667, saving model to model_09.weights.best.hdf5\n",
      "860/860 [==============================] - 29s 33ms/step - loss: 0.2873 - accuracy: 0.8923 - val_loss: 0.2367 - val_accuracy: 0.9130\n",
      "Epoch 7/10\n",
      "780/860 [==========================>...] - ETA: 2s - loss: 0.2769 - accuracy: 0.8978\n",
      "Epoch 7: val_loss improved from 0.23667 to 0.23067, saving model to model_09.weights.best.hdf5\n",
      "860/860 [==============================] - 26s 30ms/step - loss: 0.2759 - accuracy: 0.8977 - val_loss: 0.2307 - val_accuracy: 0.9168\n",
      "Epoch 8/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.2647 - accuracy: 0.9016\n",
      "Epoch 8: val_loss did not improve from 0.23067\n",
      "860/860 [==============================] - 28s 33ms/step - loss: 0.2647 - accuracy: 0.9016 - val_loss: 0.2373 - val_accuracy: 0.9086\n",
      "Epoch 9/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.2605 - accuracy: 0.9044\n",
      "Epoch 9: val_loss did not improve from 0.23067\n",
      "860/860 [==============================] - 30s 35ms/step - loss: 0.2605 - accuracy: 0.9044 - val_loss: 0.2342 - val_accuracy: 0.9152\n",
      "Epoch 10/10\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.2478 - accuracy: 0.9081\n",
      "Epoch 10: val_loss did not improve from 0.23067\n",
      "860/860 [==============================] - 28s 33ms/step - loss: 0.2482 - accuracy: 0.9080 - val_loss: 0.2330 - val_accuracy: 0.9118\n"
     ]
    }
   ],
   "source": [
    "# Mark start time\n",
    "start = time.time()\n",
    "model_09.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[checkpointer_09])\n",
    "# Calculate training time\n",
    "time_09 = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ab598fcd-9afd-479a-a164-c3066c33073f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.6088 - accuracy: 0.7752\n",
      "Epoch 1: val_loss improved from inf to 0.38893, saving model to model_10.weights.best.hdf5\n",
      "860/860 [==============================] - 29s 33ms/step - loss: 0.6086 - accuracy: 0.7752 - val_loss: 0.3889 - val_accuracy: 0.8628\n",
      "Epoch 2/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.4228 - accuracy: 0.8448\n",
      "Epoch 2: val_loss improved from 0.38893 to 0.32897, saving model to model_10.weights.best.hdf5\n",
      "860/860 [==============================] - 28s 33ms/step - loss: 0.4227 - accuracy: 0.8448 - val_loss: 0.3290 - val_accuracy: 0.8842\n",
      "Epoch 3/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3768 - accuracy: 0.8630\n",
      "Epoch 3: val_loss improved from 0.32897 to 0.30644, saving model to model_10.weights.best.hdf5\n",
      "860/860 [==============================] - 29s 33ms/step - loss: 0.3768 - accuracy: 0.8630 - val_loss: 0.3064 - val_accuracy: 0.8882\n",
      "Epoch 4/10\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.3508 - accuracy: 0.8719\n",
      "Epoch 4: val_loss improved from 0.30644 to 0.27838, saving model to model_10.weights.best.hdf5\n",
      "860/860 [==============================] - 29s 33ms/step - loss: 0.3509 - accuracy: 0.8718 - val_loss: 0.2784 - val_accuracy: 0.9010\n",
      "Epoch 5/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.3289 - accuracy: 0.8799\n",
      "Epoch 5: val_loss did not improve from 0.27838\n",
      "860/860 [==============================] - 28s 33ms/step - loss: 0.3290 - accuracy: 0.8799 - val_loss: 0.2825 - val_accuracy: 0.8938\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.3130 - accuracy: 0.8856\n",
      "Epoch 6: val_loss improved from 0.27838 to 0.26491, saving model to model_10.weights.best.hdf5\n",
      "860/860 [==============================] - 28s 33ms/step - loss: 0.3130 - accuracy: 0.8856 - val_loss: 0.2649 - val_accuracy: 0.9012\n",
      "Epoch 7/10\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.3024 - accuracy: 0.8881\n",
      "Epoch 7: val_loss improved from 0.26491 to 0.24690, saving model to model_10.weights.best.hdf5\n",
      "860/860 [==============================] - 28s 32ms/step - loss: 0.3024 - accuracy: 0.8881 - val_loss: 0.2469 - val_accuracy: 0.9082\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.2887 - accuracy: 0.8935\n",
      "Epoch 8: val_loss improved from 0.24690 to 0.23994, saving model to model_10.weights.best.hdf5\n",
      "860/860 [==============================] - 29s 34ms/step - loss: 0.2887 - accuracy: 0.8935 - val_loss: 0.2399 - val_accuracy: 0.9088\n",
      "Epoch 9/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.2787 - accuracy: 0.8960\n",
      "Epoch 9: val_loss improved from 0.23994 to 0.23240, saving model to model_10.weights.best.hdf5\n",
      "860/860 [==============================] - 30s 34ms/step - loss: 0.2787 - accuracy: 0.8961 - val_loss: 0.2324 - val_accuracy: 0.9102\n",
      "Epoch 10/10\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.2694 - accuracy: 0.9006\n",
      "Epoch 10: val_loss improved from 0.23240 to 0.22904, saving model to model_10.weights.best.hdf5\n",
      "860/860 [==============================] - 28s 33ms/step - loss: 0.2694 - accuracy: 0.9006 - val_loss: 0.2290 - val_accuracy: 0.9116\n"
     ]
    }
   ],
   "source": [
    "# Mark start time\n",
    "start = time.time()\n",
    "model_10.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[checkpointer_10])\n",
    "# Calculate training time\n",
    "time_10 = time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c006752e-2150-4cd9-9d2b-115cddc6ee8a",
   "metadata": {},
   "source": [
    "## Load models with the best validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "58649175-b7be-45ab-833a-471cbd3efeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights with the best validation accuracy\n",
    "model_01.load_weights('model_01.weights.best.hdf5')\n",
    "model_02.load_weights('model_02.weights.best.hdf5')\n",
    "model_03.load_weights('model_03.weights.best.hdf5')\n",
    "model_04.load_weights('model_04.weights.best.hdf5')\n",
    "model_05.load_weights('model_05.weights.best.hdf5')\n",
    "model_06.load_weights('model_06.weights.best.hdf5')\n",
    "model_07.load_weights('model_07.weights.best.hdf5')\n",
    "model_08.load_weights('model_08.weights.best.hdf5')\n",
    "model_09.load_weights('model_09.weights.best.hdf5')\n",
    "model_10.load_weights('model_10.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c3db7c-c364-4036-9702-ce9946cd60e8",
   "metadata": {},
   "source": [
    "## Run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ab071147-af63-4518-881d-e00a2c14a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test set\n",
    "score_01 = model_01.evaluate(x_test, y_test, verbose=0)\n",
    "score_02 = model_02.evaluate(x_test, y_test, verbose=0)\n",
    "score_03 = model_03.evaluate(x_test, y_test, verbose=0)\n",
    "score_04 = model_04.evaluate(x_test, y_test, verbose=0)\n",
    "score_05 = model_05.evaluate(x_test, y_test, verbose=0)\n",
    "score_06 = model_06.evaluate(x_test, y_test, verbose=0)\n",
    "score_07 = model_07.evaluate(x_test, y_test, verbose=0)\n",
    "score_08 = model_08.evaluate(x_test, y_test, verbose=0)\n",
    "score_09 = model_09.evaluate(x_test, y_test, verbose=0)\n",
    "score_10 = model_10.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "977bc2df-e5d3-4eb0-9ba6-ad0907aa4b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model     Architecture                              Number of parameters    Training time (s)    Accuracy\n",
      "--------  --------------------------------------  ----------------------  -------------------  ----------\n",
      "Model 1   [(32,2),(16,2), (0.3,0.3)]                              814058              259.651      0.9106\n",
      "Model 2   [(128,2),(64,2), (0.3,0.3)]                             839114              604.759      0.9132\n",
      "Model 3   [(64,4),(32,4), (0.3,0.3)]                               44906              211.3        0.8727\n",
      "Model 4   [(64,2),(32,4), (0.3,0.3)]                              109674              415.715      0.9011\n",
      "Model 5   [(64,2),(32,2), (0.2,0.2)]                              152682              341.62       0.9055\n",
      "Model 6   [(64,2),(32,2), (0.4,0.4)]                              412778              296.957      0.9017\n",
      "Model 7   [(64,2),(32,2),(32,2), (0.3,0.3,0.3)]                    89226              297.201      0.8919\n",
      "Model 8   [(128,2),(64,2),(64,2), (0.3,0.3,0.3)]                  200202              563.57       0.9046\n",
      "Model 9   [(128,2),(64,2), (0.2,0.2)]                             412778              286.728      0.9057\n",
      "Model 10  [(128,4),(64,4), (0.3,0.3)]                             412778              285.203      0.9116\n"
     ]
    }
   ],
   "source": [
    "data = [[\"Model 1\",\"[(32,2),(16,2), (0.3,0.3)]\", model_01.count_params(), time_01, score_01[1]], \n",
    "        [\"Model 2\",\"[(128,2),(64,2), (0.3,0.3)]\", model_02.count_params(), time_02, score_02[1]], \n",
    "        [\"Model 3\",\"[(64,4),(32,4), (0.3,0.3)]\", model_03.count_params(), time_03, score_03[1]], \n",
    "        [\"Model 4\",\"[(64,2),(32,4), (0.3,0.3)]\", model_04.count_params(), time_04, score_04[1]],\n",
    "        [\"Model 5\",\"[(64,2),(32,2), (0.2,0.2)]\", model_05.count_params(), time_05, score_05[1]],\n",
    "        [\"Model 6\",\"[(64,2),(32,2), (0.4,0.4)]\", model_06.count_params(), time_06, score_06[1]],\n",
    "        [\"Model 7\",\"[(64,2),(32,2),(32,2), (0.3,0.3,0.3)]\", model_07.count_params(), time_07, score_07[1]],\n",
    "        [\"Model 8\",\"[(128,2),(64,2),(64,2), (0.3,0.3,0.3)]\", model_08.count_params(), time_08, score_08[1]],\n",
    "        [\"Model 9\",\"[(128,2),(64,2), (0.2,0.2)]\", model_09.count_params(), time_09, score_09[1]],\n",
    "        [\"Model 10\",\"[(128,4),(64,4), (0.3,0.3)]\", model_10.count_params(), time_10, score_10[1]]]\n",
    "col_names = [\"Model\", \"Architecture\", \"Number of parameters\", \"Training time (s)\", \"Accuracy\"]\n",
    "print(tabulate(data, headers=col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f43ea4e-1e28-4fbe-8578-2dd88b508acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
